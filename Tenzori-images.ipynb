{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441ad7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dijan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
      "Path to dataset files: C:\\Users\\dijan\\.cache\\kagglehub\\datasets\\olgabelitskaya\\yale-face-database\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olgabelitskaya/yale-face-database\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29067d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 165 images\n",
      "Each image has 10000 pixels\n",
      "Unique labels: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Training set: (165, 10000) images\n",
      "Test set: 0 images\n",
      "[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    num_images_per_subject = [0 for _ in range(39)]  # Pretpostavljamo da ima 39 subjekata\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.startswith(\"subject\"):\n",
    "            # labela iz imena: subject01 → 1\n",
    "            label = int(filename[7:9])\n",
    "            num_images_per_subject[label - 1] += 1\n",
    "\n",
    "\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            img = img.resize((100, 100))\n",
    "\n",
    "            images.append(np.array(img, dtype=np.float32).flatten() / 255.0)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels), num_images_per_subject\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "folder_path = r\"C:\\Users\\dijan\\.cache\\kagglehub\\datasets\\olgabelitskaya\\yale-face-database\\versions\\1\\data\"\n",
    "\n",
    "images, labels, num_images_per_subject = load_images_from_folder(folder_path)\n",
    "\n",
    "print(f\"Loaded {images.shape[0]} images\")\n",
    "print(f\"Each image has {images.shape[1]} pixels\")\n",
    "print(f\"Unique labels: {np.unique(labels)}\")\n",
    "\n",
    "# Podjela na trening i test skup\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    label_images = images[labels == label]\n",
    "    n_train = int(1 * label_images.shape[0])\n",
    "    \n",
    "    train_images.append(label_images[:n_train])\n",
    "    train_labels.append(np.full(n_train, label))\n",
    "    \n",
    "    test_images.append(label_images[n_train:])\n",
    "    test_labels.append(np.full(label_images.shape[0] - n_train, label))\n",
    "    \n",
    "train_images = np.vstack(train_images)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "test_images = np.vstack(test_images)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "\n",
    "print(f\"Training set: {train_images.shape} images\")\n",
    "print(f\"Test set: {test_images.shape[0]} images\")\n",
    "print(num_images_per_subject)\n",
    "\n",
    "X = train_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3d1de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: (15, 11, 10000)\n"
     ]
    }
   ],
   "source": [
    "num_per_matrix = 11\n",
    "num_matrices = X.shape[0] // num_per_matrix\n",
    "\n",
    "tensor = X.reshape(num_matrices, num_per_matrix, X.shape[1])\n",
    "\n",
    "print(\"Tensor shape:\", tensor.shape) #(15, 11, 10000)\n",
    "\n",
    "element = tensor[0, 1, :].reshape(100, 100)  # Prvi element prvog matriksa\n",
    "img = Image.fromarray((element * 255).astype(np.uint8))\n",
    "img.show()\n",
    "\n",
    "A = np.transpose(tensor, (2, 1, 0))\n",
    "\n",
    "n_i, n_e, n_p = A.shape\n",
    "A1 = A.reshape(n_i, n_e * n_p)\n",
    "\n",
    "U, S, Vt = np.linalg.svd(A1, full_matrices=False)\n",
    "r = n_e * n_p\n",
    "F = U[:, :r]\n",
    "S_A = np.tensordot(F.T, A, axes=(1, 0))\n",
    "\n",
    "# uzmemo prvi frontalni odsječak (prva osoba, ekspresija 1)\n",
    "reduced_vector = S_A[:, 1, 0]  # svi F komponente za tu osobu i ekspresiju\n",
    "\n",
    "# vraćanje u originalni prostor pikseli\n",
    "reconstructed = F @ reduced_vector  # shape: (10000,)\n",
    "img = Image.fromarray((reconstructed.reshape(100, 100) * 255).astype(np.uint8))\n",
    "img.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f638480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
